{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/train_imputed.csv')\n",
    "test=pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/test_imputed.csv')\n",
    "test_id=pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/test_imputed.csv')\n",
    "print(train.head(5))\n",
    "print(test.head(5))\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#fmri = sns.load_dataset(\"fmri\")\n",
    "sns.set(font_scale = 4)\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 30)\n",
    "ax = sns.lineplot(x=\"Day_No\", y=\"Sales\", data=train)\n",
    "#hue=\"Course_Domain\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart = train[train['Day_No']<120]\n",
    "train_chart.head()\n",
    "\n",
    "sns.set(font_scale = 4)\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 30)\n",
    "#plt.rcParams[\"axes.labelsize\"] = 100\n",
    "ax = sns.lineplot(x=\"Day_No\", y=\"Sales\", data=train_chart)\n",
    "#hue=\"Course_Domain\",\n",
    "#hue=\"Course_Domain\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def serial(srl_no):\n",
    "    new_date = datetime.datetime(1970,1,1,0,0) + datetime.timedelta(srl_no - 1)\n",
    "    return new_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#import datetime\n",
    "train_date = train\n",
    "train_date['date']= train_date['Day_No'].apply(lambda x: serial(x))\n",
    "train_date['date'] = pd.to_datetime(train_date['date'])\n",
    "train_date.set_index('date',inplace=True)\n",
    "\n",
    "test_date=test\n",
    "test_date['date']= test_date['Day_No'].apply(lambda x: serial(x))\n",
    "test_date['date'] = pd.to_datetime(test_date['date'])\n",
    "test_date.set_index('date',inplace=True)\n",
    "\n",
    "\n",
    "#serial_date_to_string(train_date['Day_No'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Day_No</th>\n",
       "      <th>Course_ID</th>\n",
       "      <th>Course_Domain</th>\n",
       "      <th>Course_Type</th>\n",
       "      <th>Short_Promotion</th>\n",
       "      <th>Public_Holiday</th>\n",
       "      <th>Long_Promotion</th>\n",
       "      <th>Competition_Metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1972-06-01</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>1</td>\n",
       "      <td>Development</td>\n",
       "      <td>Course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-06-02</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>Development</td>\n",
       "      <td>Course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-06-03</td>\n",
       "      <td>885</td>\n",
       "      <td>885</td>\n",
       "      <td>1</td>\n",
       "      <td>Development</td>\n",
       "      <td>Course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-06-04</td>\n",
       "      <td>886</td>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>Development</td>\n",
       "      <td>Course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-06-05</td>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>Development</td>\n",
       "      <td>Course</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-07-26</td>\n",
       "      <td>548083</td>\n",
       "      <td>938</td>\n",
       "      <td>600</td>\n",
       "      <td>Software Marketing</td>\n",
       "      <td>Program</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-07-27</td>\n",
       "      <td>548084</td>\n",
       "      <td>939</td>\n",
       "      <td>600</td>\n",
       "      <td>Software Marketing</td>\n",
       "      <td>Program</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-07-28</td>\n",
       "      <td>548085</td>\n",
       "      <td>940</td>\n",
       "      <td>600</td>\n",
       "      <td>Software Marketing</td>\n",
       "      <td>Program</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-07-29</td>\n",
       "      <td>548086</td>\n",
       "      <td>941</td>\n",
       "      <td>600</td>\n",
       "      <td>Software Marketing</td>\n",
       "      <td>Program</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972-07-30</td>\n",
       "      <td>548087</td>\n",
       "      <td>942</td>\n",
       "      <td>600</td>\n",
       "      <td>Software Marketing</td>\n",
       "      <td>Program</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Day_No  Course_ID       Course_Domain Course_Type  \\\n",
       "date                                                                    \n",
       "1972-06-01     883     883          1         Development      Course   \n",
       "1972-06-02     884     884          1         Development      Course   \n",
       "1972-06-03     885     885          1         Development      Course   \n",
       "1972-06-04     886     886          1         Development      Course   \n",
       "1972-06-05     887     887          1         Development      Course   \n",
       "...            ...     ...        ...                 ...         ...   \n",
       "1972-07-26  548083     938        600  Software Marketing     Program   \n",
       "1972-07-27  548084     939        600  Software Marketing     Program   \n",
       "1972-07-28  548085     940        600  Software Marketing     Program   \n",
       "1972-07-29  548086     941        600  Software Marketing     Program   \n",
       "1972-07-30  548087     942        600  Software Marketing     Program   \n",
       "\n",
       "            Short_Promotion  Public_Holiday  Long_Promotion  \\\n",
       "date                                                          \n",
       "1972-06-01                1               0               1   \n",
       "1972-06-02                1               0               1   \n",
       "1972-06-03                1               0               1   \n",
       "1972-06-04                1               0               1   \n",
       "1972-06-05                0               0               1   \n",
       "...                     ...             ...             ...   \n",
       "1972-07-26                1               0               1   \n",
       "1972-07-27                1               0               1   \n",
       "1972-07-28                1               0               1   \n",
       "1972-07-29                1               0               1   \n",
       "1972-07-30                1               0               1   \n",
       "\n",
       "            Competition_Metric  \n",
       "date                            \n",
       "1972-06-01               0.007  \n",
       "1972-06-02               0.007  \n",
       "1972-06-03               0.007  \n",
       "1972-06-04               0.007  \n",
       "1972-06-05               0.007  \n",
       "...                        ...  \n",
       "1972-07-26               0.070  \n",
       "1972-07-27               0.070  \n",
       "1972-07-28               0.070  \n",
       "1972-07-29               0.070  \n",
       "1972-07-30               0.070  \n",
       "\n",
       "[36000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_date\n",
    "#train_train_filtered=train_date[train_date['Day_No']<801]\n",
    "#train_filtered.head(802)\n",
    "#train_val_filtered=train_date[train_date['Day_No']>800]\n",
    "#train_val_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\np8022\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-034f35747436>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_date_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Course_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_exog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Short_Promotion'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Public_Holiday'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Long_Promotion'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Competition_Metric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_endog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2969\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3021\u001b[0m         \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3023\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3024\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2405\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2407\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2408\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m   4216\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4218\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m     def drop(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4512\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4513\u001b[0m         return self._reindex_axes(\n\u001b[1;32m-> 4514\u001b[1;33m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4515\u001b[0m         ).__finalize__(self)\n\u001b[0;32m   4516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4533\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4534\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4535\u001b[1;33m                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4536\u001b[0m             )\n\u001b[0;32m   4537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4575\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4576\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4577\u001b[1;33m                 \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4578\u001b[0m             )\n\u001b[0;32m   4579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3360\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3362\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "##for testing different models against validatin dataset (day 801 to 883)\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "final_table= pd.DataFrame(columns=['Course_ID', 'Sales', 'Day_No'])\n",
    "Day_No=range(801,883)\n",
    "train_date_filtered=train_date[train_date['Day_No']<801]\n",
    "val_date=train_date[train_date['Day_No']>800]\n",
    "\n",
    "for ID in range(1,6):\n",
    "    train_train=train_date_filtered[train_date['Course_ID']==ID]\n",
    "    train_exog=train_train[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    train_endog=train_train[['Sales']]\n",
    "    \n",
    "        \n",
    "    #for x in (7,14,15,28,30):\n",
    "    model = auto_arima(train_endog,exogenous=train_exog,start_p=1,start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    #\n",
    "    print(model.aic())\n",
    "    print(ID)\n",
    "    model.fit(train_endog)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #test_test=test_date[test_date['Course_ID']==ID]    \n",
    "    #train_train=train_train_filtered[train_train_filtered['Course_ID']==ID]\n",
    "    val_exog=val_date.loc[val_date['Course_ID']==ID,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    #val_exog=train_val_filtered[train_train_filtered['Course_ID']==ID],['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    forecast = model.predict(n_periods=len(val_exog),exogenous=val_exog)\n",
    "    \n",
    "    #,exog=val_exog\n",
    "    #forecast\n",
    "    \n",
    "    #print(forecast)\n",
    "    s=pd.DataFrame({'Course_ID':ID,'Sales':forecast,'Day_No':Day_No,'m':7})\n",
    "    #print(s)\n",
    "    final_table=final_table.append(s,ignore_index=True)\n",
    "\n",
    "final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_testing_withexog_m7_course(1-5)attempt2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Surprisingly, adding exogenous variables brings down the prediction accuracy as revealed in a test for 5 courses \n",
    "##actual prediction for test data\n",
    "\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "final_table= pd.DataFrame(columns=['Course_ID', 'Sales', 'Day_No'])\n",
    "Day_No=range(883,943)\n",
    "\n",
    "for ID in range(176,601):\n",
    "    train_train=train_date[train_date['Course_ID']==ID]\n",
    "    train_exog=train_train[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    train_endog=train_train[['Sales']]\n",
    "    \n",
    "        \n",
    "    #for x in (7,14,15,28,30):\n",
    "    model = auto_arima(train_endog,exogenous=train_exog,start_p=1,start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    #\n",
    "    print(model.aic())\n",
    "    print(ID)\n",
    "    model.fit(train_endog)\n",
    "    \n",
    "    \n",
    "    #test_test=test_date[test_date['Course_ID']==ID]    \n",
    "    #train_train=train_train_filtered[train_train_filtered['Course_ID']==ID]\n",
    "    test_exog=test_date.loc[test_date['Course_ID']==ID,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    #val_exog=train_val_filtered[train_train_filtered['Course_ID']==ID],['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    forecast = model.predict(n_periods=len(test_exog),exogenous=test_exog)\n",
    "    \n",
    "    #,exog=val_exog\n",
    "    #forecast\n",
    "    \n",
    "    #print(forecast)\n",
    "    s=pd.DataFrame({'Course_ID':ID,'Sales':forecast,'Day_No':Day_No,'m':7})\n",
    "    #print(s)\n",
    "    final_table=final_table.append(s,ignore_index=True)\n",
    "\n",
    "final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_forecasting_withexog_m7_course(176-600).csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_exog=train_val_filtered.loc[train_val_filtered['Course_ID']==1,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "#train_val_filtered[train_val_filtered['Course_ID']==1].[train_val_filtered[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "#val_exog\n",
    "final_table\n",
    "#final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_forecasting_withexog_m7_course(1-174).csv',index=False)\n",
    "\n",
    "#train_exog\n",
    "#final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_testing_exog_m7_course1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font='IPAGothic')\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(train_time,freq=7)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "stepwise_model = auto_arima(train_time, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=15,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "#print(stepwise_model.aic())\n",
    "\n",
    "stepwise_model.fit(train_model)\n",
    "future_forecast = stepwise_model.predict(n_periods=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "#data = pd.read_csv('international-airline-passengers.csv')\n",
    "\n",
    "#divide into train and validation set\n",
    "train = train_time[:int(0.7*(len(train_time)))]\n",
    "valid = train_time[int(0.7*(len(train_time))):]\n",
    "\n",
    "#preprocessing (since arima takes univariate series as input)\n",
    "#train.drop('Month',axis=1,inplace=True)\n",
    "#valid.drop('Month',axis=1,inplace=True)\n",
    "\n",
    "#plotting the data\n",
    "#train['International airline passengers'].plot()\n",
    "#valid['International airline passengers'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "\n",
    "forecast = model.predict(n_periods=len(valid))\n",
    "forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])\n",
    "\n",
    "#plot the predictions for validation set\n",
    "plt.plot(train, label='Train')\n",
    "plt.plot(valid, label='Valid')\n",
    "plt.plot(forecast, label='Prediction')\n",
    "\n",
    "sns.set(font_scale = 1)\n",
    "plt.rcParams[\"figure.figsize\"] = (100, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['ID','Course_ID']\n",
    "\n",
    "#promotion and holiday flags to be tried as objects seperately\n",
    "\n",
    "for x in train.columns:\n",
    "    if x in list:\n",
    "        train[x]=train[x].astype(np.object)        \n",
    "    \n",
    "for x in test.columns:\n",
    "    if x in list:\n",
    "        test[x]=test[x].astype(np.object)\n",
    "\n",
    "test=test.drop(['ID'],axis=1)\n",
    "train = train.drop(['ID','User_Traffic'],axis=1)\n",
    "\n",
    "print(test.dtypes)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Course_ID','Course_Domain','Course_Type'],drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Course_ID','Course_Domain','Course_Type'],drop_first=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x='Competition_Metric', y=\"Sales\", data=train)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "#plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "#plt.autofmt_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#fmri = sns.load_dataset(\"fmri\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "ax = sns.lineplot(x=\"User_Traffic\", y=\"Sales\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for grodsearch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "MSE = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "#RMSE = sqrt(mean_squared_error())\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "#RMSLE=np.sqrt(mean_squared_log_error( y, predictions ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for gridsearch with stratkfold\\n\",\n",
    "X,y=train.drop(['Sales'],axis=1),train.Sales\n",
    "params = {'n_estimators': [600,1000],\n",
    "        'reg_lambda' : [4,9],\n",
    "        'learning_rate' : [0.03,0.13],\n",
    "        'depth' : [4,7],\n",
    "        'bagging_temperature' : [1]\n",
    "        }                        \n",
    "from catboost import CatBoostClassifier,Pool, cv,CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2, random_state=13, shuffle=True)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes =='object')[0]\n",
    "catb = CatBoostRegressor(cat_features=categorical_features_indices,random_seed=13,early_stopping_rounds=100)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 13)\n",
    "print('start_gridsearch')\n",
    "grid = GridSearchCV(estimator=catb, param_grid=params, cv=skf.split(X,y),verbose=100,scoring = MSE )\n",
    "print('start_fit')\n",
    "grid.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Catreg_tuning_v1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catboost without gridsearch\n",
    "    \n",
    "from catboost import CatBoostClassifier,Pool, cv,CatBoostRegressor\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "X,y=train.drop(['Sales'],axis=1),train.Sales\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,random_state = 13)\n",
    "categorical_features_indices = np.where(X_train.dtypes =='object')[0]\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "cat_model5 = CatBoostRegressor(n_estimators=1200, # use large n_estimators deliberately to make use of the early stopping\n",
    "                         reg_lambda=4,\n",
    "                         eval_metric='RMSE',\n",
    "                         random_seed=13,\n",
    "                         learning_rate = 0.13,\n",
    "                         depth = 7,\n",
    "                         bagging_temperature = 1.0,cat_features=categorical_features_indices)\n",
    "\n",
    "cat_model5.fit(X_train.values,y_train.values,eval_set=(X_val, y_val),plot=False,use_best_model=True,verbose_eval=50)\n",
    "pred = cat_model5.predict(test)\n",
    "y_pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=rf.predict(dftest_dum.drop('id',axis=1))\n",
    "print(np.mean(err,0))\n",
    "y_pred=np.mean(y_pred_tot,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'ID':test_id.ID,'Sales':y_pred})\n",
    "s.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Catreg_v0.1(RMSE for tuning_flagsasobjects).csv',index=False)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart=train\n",
    "train_chart['year_month']=train_chart['Year'].astype(str)+train_chart['Month'].astype(str)\n",
    "print(train_chart.head())\n",
    "print(train_chart.describe())\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x='year_month', y=\"case_count\", data=train_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart_line=train.groupby(['application_date'])['case_count'].sum().reset_index()\n",
    "train_chart_line.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "sns.lineplot(x='application_date', y='case_count', data=train_chart_line)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 6)\n",
    "plt.rcParams[\"xtick.labelsize\"] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=test\n",
    "\n",
    "test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('application_date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(predict, actual):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    error = (predict - actual)/actual\n",
    "    abs_error = np.absolute(error)\n",
    "    \n",
    "    #square_distance = distance ** 2\n",
    "\n",
    "    #mean_square_distance = square_distance.mean()\n",
    "\n",
    "    score = np.mean(abs_error)\n",
    "\n",
    "    return score\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "mape_score = make_scorer(mape,greater_is_better = False)\n",
    "\n",
    "#gsSVR = GridSearchCV(...scoring=rmse_score...)\n",
    "#gsSVR.fit(X_train,Y_train)\n",
    "#SVR_best = gsSVR.best_estimator_\n",
    "#print(gsSVR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for gridsearch/tuning\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.8,1],\n",
    "        'max_depth': [ 5, 8,10],\n",
    "        'learning_rate':[0.01,0.1,0.3],\n",
    "        'n_estimators':[30,50,80]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "Xd,yd=train.drop('case_count',axis=1),train.case_count\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "xg = xgb.XGBRegressor(eval_metric='auc',verbose=100, nthread=4)          \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3, random_state=13, shuffle=True)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=xg, param_grid=params, n_jobs=4,scoring=mape_score, cv=skf.split(Xd,yd), verbose=100 )\n",
    "grid.fit(Xd, yd)\n",
    "#print('\\n All results:')\n",
    "#print(grid.cv_results_)\n",
    "#print('\\n Best estimator:')\n",
    "#print(grid.best_estimator_)\n",
    "#print('\\n Best score:')\n",
    "#print(grid.best_score_ * 2 - 1)\n",
    "#print('\\n Best parameters:')\n",
    "#print(grid.best_params_)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    " \n",
    "results.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/LnTFS/Outputs/XGB_tuning_aggregated_v0.3_saved.csv', index=False)\n",
    "#y_test = grid.best_estimator_.predict_proba(test)\n",
    "#results_df = pd.DataFrame(data={'id':test_df['id'], 'target':y_test[:,1]})\n",
    "#results_df.to_csv('submission-grid-search-xgb-porto-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#XGBoost code,using tuned models to predict\n",
    "\n",
    "X,y=train.drop('case_count',axis=1),train.case_count\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(eval_metric='mae',learning_rate = 0.1,\n",
    "                max_depth = 10,colsample_bytree=1, subsample=0.6, n_estimators = 50,verbose=50)\n",
    "\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "#fold=StratifiedKFold(n_splits=5,shuffle=True,random_state=1994)\n",
    "\n",
    "#for train_index, test_index in fold.split(X,y):\n",
    "#    X_train, X_test = Xd.iloc[train_index], Xd.iloc[test_index]\n",
    "#    y_train, y_test = yd[train_index], yd[test_index]\n",
    "print('start')\n",
    "xg_reg.fit(X,y)\n",
    "#    print('pred...')\n",
    "#    p=xg_reg.predict(X_test)\n",
    "#    print(\"err: \",100*np.sqrt(mean_squared_error(y_test,p)))\n",
    "#    err.append(100*np.sqrt(mean_squared_error(y_test,p)))\n",
    "pred = xg_reg.predict(test)\n",
    "y_pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=rf.predict(dftest_dum.drop('id',axis=1))\n",
    "print(np.mean(err,0))\n",
    "y_pred=np.mean(y_pred_tot,0)\n",
    "print(y_pred)\n",
    "\n",
    "s=pd.DataFrame({'case_count':y_pred})\n",
    "s.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/LnTFS/Outputs/XGB_Aggregated_Tuned(MAPE)_0.4_saved.csv',index=False)\n",
    "s.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
