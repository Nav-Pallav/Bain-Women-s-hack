{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/train_imputed.csv')\n",
    "test=pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/test_imputed.csv')\n",
    "test_id=pd.read_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Inputs/test_imputed.csv')\n",
    "print(train.head(5))\n",
    "print(test.head(5))\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#fmri = sns.load_dataset(\"fmri\")\n",
    "sns.set(font_scale = 4)\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 30)\n",
    "ax = sns.lineplot(x=\"Day_No\", y=\"Sales\", data=train)\n",
    "#hue=\"Course_Domain\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart = train[train['Day_No']<120]\n",
    "train_chart.head()\n",
    "\n",
    "sns.set(font_scale = 4)\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 30)\n",
    "#plt.rcParams[\"axes.labelsize\"] = 100\n",
    "ax = sns.lineplot(x=\"Day_No\", y=\"Sales\", data=train_chart)\n",
    "#hue=\"Course_Domain\",\n",
    "#hue=\"Course_Domain\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def serial(srl_no):\n",
    "    new_date = datetime.datetime(1970,1,1,0,0) + datetime.timedelta(srl_no - 1)\n",
    "    return new_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#import datetime\n",
    "train_date = train\n",
    "train_date['date']= train_date['Day_No'].apply(lambda x: serial(x))\n",
    "train_date['date'] = pd.to_datetime(train_date['date'])\n",
    "train_date.set_index('date',inplace=True)\n",
    "\n",
    "test_date=test\n",
    "test_date['date']= test_date['Day_No'].apply(lambda x: serial(x))\n",
    "test_date['date'] = pd.to_datetime(test_date['date'])\n",
    "test_date.set_index('date',inplace=True)\n",
    "\n",
    "\n",
    "#serial_date_to_string(train_date['Day_No'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Get dummies\n",
    "train_date=pd.get_dummies(train_date,drop_first=True)\n",
    "test_date=pd.get_dummies(test_date,drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled=pd.DataFrame(train_date['Competition_Metric'])\n",
    "test_scaled=pd.DataFrame(test_date['Competition_Metric'])\n",
    "\n",
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Adding scaling block   #########\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Scaler = StandardScaler()\n",
    "Scaler.fit(train_scaled)\n",
    "train_scaled = Scaler.transform(train_scaled)\n",
    "\n",
    "Scaler.fit(test_scaled)\n",
    "test_scaled = Scaler.transform(test_scaled)\n",
    "\n",
    "test_scaled\n",
    "#foot_fall_X_test = Scaler.transform(foot_fall_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date['Competition_Metric']=train_scaled\n",
    "test_date['Competition_Metric']=test_scaled\n",
    "#test_date.columns=tt_col\n",
    "test_date\n",
    "#train_train_filtered=train_date[train_date['Day_No']<801]\n",
    "#train_filtered.head(802)\n",
    "#train_val_filtered=train_date[train_date['Day_No']>800]\n",
    "#train_val_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for testing different models against validatin dataset (day 801 to 883)\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "final_table= pd.DataFrame(columns=['Course_ID', 'Sales', 'Day_No'])\n",
    "Day_No=range(801,883)\n",
    "train_date_filtered=train_date[train_date['Day_No']<801]\n",
    "val_date=train_date[train_date['Day_No']>800]\n",
    "\n",
    "for ID in range(1,2):\n",
    "    train_train=train_date_filtered[train_date['Course_ID']==ID]\n",
    "    train_exog=train_train[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    train_endog=train_train[['Sales']]\n",
    "    \n",
    "        \n",
    "    #for x in (7,14,15,28,30):\n",
    "    model = auto_arima(train_endog,exogenous=train_exog,start_p=1,start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    #\n",
    "    print(model.aic())\n",
    "    print(ID)\n",
    "    model.fit(train_endog)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #test_test=test_date[test_date['Course_ID']==ID]    \n",
    "    #train_train=train_train_filtered[train_train_filtered['Course_ID']==ID]\n",
    "    val_exog=val_date.loc[val_date['Course_ID']==ID,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    #val_exog=train_val_filtered[train_train_filtered['Course_ID']==ID],['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    forecast = model.predict(n_periods=len(val_exog),exogenous=val_exog)\n",
    "    \n",
    "    #,exog=val_exog\n",
    "    #forecast\n",
    "    \n",
    "    #print(forecast)\n",
    "    s=pd.DataFrame({'Course_ID':ID,'Sales':forecast,'Day_No':Day_No,'m':7})\n",
    "    #print(s)\n",
    "    final_table=final_table.append(s,ignore_index=True)\n",
    "\n",
    "final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_testing_withexog_m7_course(1)attempt3(scaledcomp.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",'Course_Domain_Development', 'Course_Domain_Finance & Accounting',\n",
    "       'Course_Domain_Software Marketing', 'Course_Type_Degree',\n",
    "       'Course_Type_Program'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Surprisingly, adding exogenous variables brings down the prediction accuracy as revealed in a test for 5 courses \n",
    "##actual prediction for test data\n",
    "\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "final_table= pd.DataFrame(columns=['Course_ID', 'Sales', 'Day_No'])\n",
    "Day_No=range(883,943)\n",
    "\n",
    "for ID in range(176,601):\n",
    "    train_train=train_date[train_date['Course_ID']==ID]\n",
    "    train_exog=train_train[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    train_endog=train_train[['Sales']]\n",
    "    \n",
    "        \n",
    "    #for x in (7,14,15,28,30):\n",
    "    model = auto_arima(train_endog,exogenous=train_exog,start_p=1,start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    #\n",
    "    print(model.aic())\n",
    "    print(ID)\n",
    "    model.fit(train_endog)\n",
    "    \n",
    "    \n",
    "    #test_test=test_date[test_date['Course_ID']==ID]    \n",
    "    #train_train=train_train_filtered[train_train_filtered['Course_ID']==ID]\n",
    "    test_exog=test_date.loc[test_date['Course_ID']==ID,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    #val_exog=train_val_filtered[train_train_filtered['Course_ID']==ID],['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "    forecast = model.predict(n_periods=len(test_exog),exogenous=test_exog)\n",
    "    \n",
    "    #,exog=val_exog\n",
    "    #forecast\n",
    "    \n",
    "    #print(forecast)\n",
    "    s=pd.DataFrame({'Course_ID':ID,'Sales':forecast,'Day_No':Day_No,'m':7})\n",
    "    #print(s)\n",
    "    final_table=final_table.append(s,ignore_index=True)\n",
    "\n",
    "final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_forecasting_withexog_m7_course(176-600).csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_exog=train_val_filtered.loc[train_val_filtered['Course_ID']==1,['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "#train_val_filtered[train_val_filtered['Course_ID']==1].[train_val_filtered[['Short_Promotion','Public_Holiday','Long_Promotion','Competition_Metric']]\n",
    "#val_exog\n",
    "final_table\n",
    "#final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_forecasting_withexog_m7_course(1-174).csv',index=False)\n",
    "\n",
    "#train_exog\n",
    "#final_table.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Arima_testing_exog_m7_course1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font='IPAGothic')\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(train_time,freq=7)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "stepwise_model = auto_arima(train_time, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=15,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "#print(stepwise_model.aic())\n",
    "\n",
    "stepwise_model.fit(train_model)\n",
    "future_forecast = stepwise_model.predict(n_periods=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "#data = pd.read_csv('international-airline-passengers.csv')\n",
    "\n",
    "#divide into train and validation set\n",
    "train = train_time[:int(0.7*(len(train_time)))]\n",
    "valid = train_time[int(0.7*(len(train_time))):]\n",
    "\n",
    "#preprocessing (since arima takes univariate series as input)\n",
    "#train.drop('Month',axis=1,inplace=True)\n",
    "#valid.drop('Month',axis=1,inplace=True)\n",
    "\n",
    "#plotting the data\n",
    "#train['International airline passengers'].plot()\n",
    "#valid['International airline passengers'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "\n",
    "forecast = model.predict(n_periods=len(valid))\n",
    "forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])\n",
    "\n",
    "#plot the predictions for validation set\n",
    "plt.plot(train, label='Train')\n",
    "plt.plot(valid, label='Valid')\n",
    "plt.plot(forecast, label='Prediction')\n",
    "\n",
    "sns.set(font_scale = 1)\n",
    "plt.rcParams[\"figure.figsize\"] = (100, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['ID','Course_ID']\n",
    "\n",
    "#promotion and holiday flags to be tried as objects seperately\n",
    "\n",
    "for x in train.columns:\n",
    "    if x in list:\n",
    "        train[x]=train[x].astype(np.object)        \n",
    "    \n",
    "for x in test.columns:\n",
    "    if x in list:\n",
    "        test[x]=test[x].astype(np.object)\n",
    "\n",
    "test=test.drop(['ID'],axis=1)\n",
    "train = train.drop(['ID','User_Traffic'],axis=1)\n",
    "\n",
    "print(test.dtypes)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Course_ID','Course_Domain','Course_Type'],drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Course_ID','Course_Domain','Course_Type'],drop_first=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x='Competition_Metric', y=\"Sales\", data=train)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "#plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "#plt.autofmt_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#fmri = sns.load_dataset(\"fmri\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "ax = sns.lineplot(x=\"User_Traffic\", y=\"Sales\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for grodsearch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "MSE = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "#RMSE = sqrt(mean_squared_error())\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "#RMSLE=np.sqrt(mean_squared_log_error( y, predictions ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for gridsearch with stratkfold\\n\",\n",
    "X,y=train.drop(['Sales'],axis=1),train.Sales\n",
    "params = {'n_estimators': [600,1000],\n",
    "        'reg_lambda' : [4,9],\n",
    "        'learning_rate' : [0.03,0.13],\n",
    "        'depth' : [4,7],\n",
    "        'bagging_temperature' : [1]\n",
    "        }                        \n",
    "from catboost import CatBoostClassifier,Pool, cv,CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2, random_state=13, shuffle=True)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes =='object')[0]\n",
    "catb = CatBoostRegressor(cat_features=categorical_features_indices,random_seed=13,early_stopping_rounds=100)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 13)\n",
    "print('start_gridsearch')\n",
    "grid = GridSearchCV(estimator=catb, param_grid=params, cv=skf.split(X,y),verbose=100,scoring = MSE )\n",
    "print('start_fit')\n",
    "grid.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Catreg_tuning_v1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catboost without gridsearch\n",
    "    \n",
    "from catboost import CatBoostClassifier,Pool, cv,CatBoostRegressor\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "X,y=train.drop(['Sales'],axis=1),train.Sales\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,random_state = 13)\n",
    "categorical_features_indices = np.where(X_train.dtypes =='object')[0]\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "cat_model5 = CatBoostRegressor(n_estimators=1200, # use large n_estimators deliberately to make use of the early stopping\n",
    "                         reg_lambda=4,\n",
    "                         eval_metric='RMSE',\n",
    "                         random_seed=13,\n",
    "                         learning_rate = 0.13,\n",
    "                         depth = 7,\n",
    "                         bagging_temperature = 1.0,cat_features=categorical_features_indices)\n",
    "\n",
    "cat_model5.fit(X_train.values,y_train.values,eval_set=(X_val, y_val),plot=False,use_best_model=True,verbose_eval=50)\n",
    "pred = cat_model5.predict(test)\n",
    "y_pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=rf.predict(dftest_dum.drop('id',axis=1))\n",
    "print(np.mean(err,0))\n",
    "y_pred=np.mean(y_pred_tot,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'ID':test_id.ID,'Sales':y_pred})\n",
    "s.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/Womens Hack/Outputs/Catreg_v0.1(RMSE for tuning_flagsasobjects).csv',index=False)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart=train\n",
    "train_chart['year_month']=train_chart['Year'].astype(str)+train_chart['Month'].astype(str)\n",
    "print(train_chart.head())\n",
    "print(train_chart.describe())\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x='year_month', y=\"case_count\", data=train_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart_line=train.groupby(['application_date'])['case_count'].sum().reset_index()\n",
    "train_chart_line.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "sns.lineplot(x='application_date', y='case_count', data=train_chart_line)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 6)\n",
    "plt.rcParams[\"xtick.labelsize\"] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=test\n",
    "\n",
    "test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('application_date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(predict, actual):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    error = (predict - actual)/actual\n",
    "    abs_error = np.absolute(error)\n",
    "    \n",
    "    #square_distance = distance ** 2\n",
    "\n",
    "    #mean_square_distance = square_distance.mean()\n",
    "\n",
    "    score = np.mean(abs_error)\n",
    "\n",
    "    return score\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "mape_score = make_scorer(mape,greater_is_better = False)\n",
    "\n",
    "#gsSVR = GridSearchCV(...scoring=rmse_score...)\n",
    "#gsSVR.fit(X_train,Y_train)\n",
    "#SVR_best = gsSVR.best_estimator_\n",
    "#print(gsSVR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate code for gridsearch/tuning\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.8,1],\n",
    "        'max_depth': [ 5, 8,10],\n",
    "        'learning_rate':[0.01,0.1,0.3],\n",
    "        'n_estimators':[30,50,80]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "Xd,yd=train.drop('case_count',axis=1),train.case_count\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "xg = xgb.XGBRegressor(eval_metric='auc',verbose=100, nthread=4)          \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3, random_state=13, shuffle=True)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=xg, param_grid=params, n_jobs=4,scoring=mape_score, cv=skf.split(Xd,yd), verbose=100 )\n",
    "grid.fit(Xd, yd)\n",
    "#print('\\n All results:')\n",
    "#print(grid.cv_results_)\n",
    "#print('\\n Best estimator:')\n",
    "#print(grid.best_estimator_)\n",
    "#print('\\n Best score:')\n",
    "#print(grid.best_score_ * 2 - 1)\n",
    "#print('\\n Best parameters:')\n",
    "#print(grid.best_params_)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    " \n",
    "results.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/LnTFS/Outputs/XGB_tuning_aggregated_v0.3_saved.csv', index=False)\n",
    "#y_test = grid.best_estimator_.predict_proba(test)\n",
    "#results_df = pd.DataFrame(data={'id':test_df['id'], 'target':y_test[:,1]})\n",
    "#results_df.to_csv('submission-grid-search-xgb-porto-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#XGBoost code,using tuned models to predict\n",
    "\n",
    "X,y=train.drop('case_count',axis=1),train.case_count\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(eval_metric='mae',learning_rate = 0.1,\n",
    "                max_depth = 10,colsample_bytree=1, subsample=0.6, n_estimators = 50,verbose=50)\n",
    "\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "#fold=StratifiedKFold(n_splits=5,shuffle=True,random_state=1994)\n",
    "\n",
    "#for train_index, test_index in fold.split(X,y):\n",
    "#    X_train, X_test = Xd.iloc[train_index], Xd.iloc[test_index]\n",
    "#    y_train, y_test = yd[train_index], yd[test_index]\n",
    "print('start')\n",
    "xg_reg.fit(X,y)\n",
    "#    print('pred...')\n",
    "#    p=xg_reg.predict(X_test)\n",
    "#    print(\"err: \",100*np.sqrt(mean_squared_error(y_test,p)))\n",
    "#    err.append(100*np.sqrt(mean_squared_error(y_test,p)))\n",
    "pred = xg_reg.predict(test)\n",
    "y_pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=rf.predict(dftest_dum.drop('id',axis=1))\n",
    "print(np.mean(err,0))\n",
    "y_pred=np.mean(y_pred_tot,0)\n",
    "print(y_pred)\n",
    "\n",
    "s=pd.DataFrame({'case_count':y_pred})\n",
    "s.to_csv('C:/Users/np8022/Desktop/Analytics Vidhya competition/LnTFS/Outputs/XGB_Aggregated_Tuned(MAPE)_0.4_saved.csv',index=False)\n",
    "s.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
